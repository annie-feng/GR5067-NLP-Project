{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import enchant\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150232 entries, 0 to 150231\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   business_id  150232 non-null  object \n",
      " 1   cool         150232 non-null  int64  \n",
      " 2   date         150232 non-null  object \n",
      " 3   funny        150232 non-null  float64\n",
      " 4   review_id    150232 non-null  object \n",
      " 5   stars        150232 non-null  float64\n",
      " 6   text         150232 non-null  object \n",
      " 7   useful       150232 non-null  float64\n",
      " 8   user_id      150232 non-null  object \n",
      "dtypes: float64(3), int64(1), object(5)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/beibeifeng/Desktop/School/2020fall/5067 NLP/Project/data/train_reviews.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 10,000 samples from the original data\n",
    "selected_data = data.sample(30000, random_state = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['high', 'low', 'low', 'high', 'high', 'low', 'high', 'high', 'high', 'high']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a binary response for each review, review with stars > 3 is assigned as \"high\", otherwise is assigned as\"low\"\n",
    "binary = []\n",
    "for i in selected_data.stars:\n",
    "    if i >= 3:\n",
    "        binary.append(\"high\")\n",
    "    elif i < 3:\n",
    "        binary.append(\"low\")\n",
    "binary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data['binary'] = binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97248</td>\n",
       "      <td>WunR7VclAddvbCnc-97jzg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eedlPRo631GSaNX_DaphkQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes, believe it or not there is really good So...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tgFn7JadPQJ8aYdwIRi8aA</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127659</td>\n",
       "      <td>6vNMmkttsHkW1THWiP50xg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-06-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>EDD8yhtd3LQKO95CyOl_MQ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>First tip the whole groupon thing is a sham as...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rLpq9zNFLgyVYQrN8Gn-Zg</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16213</td>\n",
       "      <td>EWmwbOm_4UhOtvLaBzHpPA</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FDDFJlUc6kIM_ZTg_23Xsw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The Skinny: overcooked pasta, wilted iceberg a...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yXYuW-2Q0X7f0a9MHyERgw</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121599</td>\n",
       "      <td>db12Hn9hdoE-Ne4_NsVKSw</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FEe6cMH54x7Vgn_NXl3mEA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I really wanted to love this place. I really d...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wjejB1QIPsnFOVUmNjaHaA</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119819</td>\n",
       "      <td>IpLvJEjb4AN8eWq5NE2TVA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZdvF50_PGujN1g1Juur_lw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>We flew on Delta in and out of PSHIA. As an Ai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yiHXyCxPenNg5ZWCXF95qQ</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             business_id  cool        date  funny  \\\n",
       "0   97248  WunR7VclAddvbCnc-97jzg     0  2014-07-23    0.0   \n",
       "1  127659  6vNMmkttsHkW1THWiP50xg     0  2015-06-17    1.0   \n",
       "2   16213  EWmwbOm_4UhOtvLaBzHpPA     3  2010-08-27    4.0   \n",
       "3  121599  db12Hn9hdoE-Ne4_NsVKSw     0  2015-04-20    0.0   \n",
       "4  119819  IpLvJEjb4AN8eWq5NE2TVA     0  2015-04-02    0.0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eedlPRo631GSaNX_DaphkQ    4.0   \n",
       "1  EDD8yhtd3LQKO95CyOl_MQ    2.0   \n",
       "2  FDDFJlUc6kIM_ZTg_23Xsw    2.0   \n",
       "3  FEe6cMH54x7Vgn_NXl3mEA    3.0   \n",
       "4  ZdvF50_PGujN1g1Juur_lw    4.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Yes, believe it or not there is really good So...     0.0   \n",
       "1  First tip the whole groupon thing is a sham as...     1.0   \n",
       "2  The Skinny: overcooked pasta, wilted iceberg a...     3.0   \n",
       "3  I really wanted to love this place. I really d...     5.0   \n",
       "4  We flew on Delta in and out of PSHIA. As an Ai...     1.0   \n",
       "\n",
       "                  user_id binary  \n",
       "0  tgFn7JadPQJ8aYdwIRi8aA   high  \n",
       "1  rLpq9zNFLgyVYQrN8Gn-Zg    low  \n",
       "2  yXYuW-2Q0X7f0a9MHyERgw    low  \n",
       "3  wjejB1QIPsnFOVUmNjaHaA   high  \n",
       "4  yiHXyCxPenNg5ZWCXF95qQ   high  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   index        30000 non-null  int64  \n",
      " 1   business_id  30000 non-null  object \n",
      " 2   cool         30000 non-null  int64  \n",
      " 3   date         30000 non-null  object \n",
      " 4   funny        30000 non-null  float64\n",
      " 5   review_id    30000 non-null  object \n",
      " 6   stars        30000 non-null  float64\n",
      " 7   text         30000 non-null  object \n",
      " 8   useful       30000 non-null  float64\n",
      " 9   user_id      30000 non-null  object \n",
      " 10  binary       30000 non-null  object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "selected_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high    25514\n",
       "low      4486\n",
       "Name: binary, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, believe it or not there is really good Soul Food in Ahwatukee.  Love the breaded catfish, the fried chicken, and especially the greens.  Lots of flavor to them, and they're not drenched in butter.  The mac and cheese is good.  The cornbread is a bit of a disappointment, as is the sauteed cabbage, but by and large the food is very good, and the owners really friendly and proud of what they're doing.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text, i.e. remove punctuation, change all characters in lower case\n",
    "def clean_text(str_in):\n",
    "    import re\n",
    "    tmp = re.sub(\"[^A-z ]+\", \"\", str_in.lower())\n",
    "    return tmp\n",
    "\n",
    "selected_data['clean_review'] = selected_data.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes believe it or not there is really good soul food in ahwatukee  love the breaded catfish the fried chicken and especially the greens  lots of flavor to them and theyre not drenched in butter  the mac and cheese is good  the cornbread is a bit of a disappointment as is the sauteed cabbage but by and large the food is very good and the owners really friendly and proud of what theyre doing'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.clean_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if words are in english dictionary\n",
    "def check_en(var):\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    tmp = var.split() #tokenize\n",
    "    tmp_list = list()\n",
    "    for word in tmp:\n",
    "        if d.check(word):\n",
    "            tmp_list.append(word)\n",
    "    tmp = ' '.join(tmp_list)\n",
    "    return tmp\n",
    "\n",
    "selected_data['clean_review'] = selected_data.clean_review.apply(check_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes believe it or not there is really good soul food in love the breaded catfish the fried chicken and especially the greens lots of flavor to them and not drenched in butter the mac and cheese is good the cornbread is a bit of a disappointment as is the sauteed cabbage but by and large the food is very good and the owners really friendly and proud of what doing'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.clean_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "def remove_stopwords(var):\n",
    "    my_sw = (stopwords.words('english'))\n",
    "    tmp = var.split()\n",
    "    tmp = [word for word in tmp if my_sw.count(word) == 0]\n",
    "    tmp = ' '.join(tmp)\n",
    "    return tmp\n",
    "\n",
    "selected_data['clean_review'] = selected_data.clean_review.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes believe really good soul food love breaded catfish fried chicken especially greens lots flavor drenched butter mac cheese good cornbread bit disappointment sauteed cabbage large food good owners really friendly proud'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.clean_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "def my_stem(var):\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stem = PorterStemmer()\n",
    "    tmp = var.split()\n",
    "    tmp = [stem.stem(word) for word in tmp]\n",
    "    tmp = ' '.join(tmp)\n",
    "    return tmp\n",
    "\n",
    "selected_data['clean_review'] = selected_data.clean_review.apply(my_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ye believ realli good soul food love bread catfish fri chicken especi green lot flavor drench butter mac chees good cornbread bit disappoint saute cabbag larg food good owner realli friendli proud'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_data.clean_review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorize text\n",
    "def my_tfidf(df_in):\n",
    "    tf_idf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vec_out = pd.DataFrame(tf_idf_vectorizer.fit_transform(df_in).toarray())\n",
    "    tfidf_vec_out.columns = tf_idf_vectorizer.get_feature_names()\n",
    "    return tfidf_vec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aah</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abacu</th>\n",
       "      <th>abalon</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbrevi</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>...</th>\n",
       "      <th>zinnia</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippi</th>\n",
       "      <th>zither</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 14594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aah   ab  aback  abacu  abalon  abandon  abbey  abbot  abbrevi  \\\n",
       "0      0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "1      0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "2      0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "3      0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "4      0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "...    ...  ...    ...    ...     ...      ...    ...    ...      ...   \n",
       "29995  0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "29996  0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "29997  0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "29998  0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "29999  0.0  0.0    0.0    0.0     0.0      0.0    0.0    0.0      0.0   \n",
       "\n",
       "       abdomen  ...  zinnia  zip  zipper  zippi  zither  zombi  zone  zoo  \\\n",
       "0          0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "1          0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "2          0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "3          0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "4          0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "...        ...  ...     ...  ...     ...    ...     ...    ...   ...  ...   \n",
       "29995      0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "29996      0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "29997      0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "29998      0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "29999      0.0  ...     0.0  0.0     0.0    0.0     0.0    0.0   0.0  0.0   \n",
       "\n",
       "       zoom  zucchini  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  \n",
       "...     ...       ...  \n",
       "29995   0.0       0.0  \n",
       "29996   0.0       0.0  \n",
       "29997   0.0       0.0  \n",
       "29998   0.0       0.0  \n",
       "29999   0.0       0.0  \n",
       "\n",
       "[30000 rows x 14594 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text = my_tfidf(selected_data.clean_review)\n",
    "tfidf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models - Predict Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_text, selected_data.stars, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 14594), (6000, 14594), (24000,), (6000,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 70.44166666666666 %\n",
      "Test Accuracy is 48.266666666666666 %\n"
     ]
    }
   ],
   "source": [
    "# build model and fit training data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# Training & Test accuracy\n",
    "print(\"Training Accuracy is\", clf.score(X_train, y_train)*100, \"%\")\n",
    "print(\"Test Accuracy is\", clf.score(X_test, y_test)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.479693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.482667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.455023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "precision  0.479693\n",
       "recall     0.482667\n",
       "fscore     0.455023\n",
       "support         NaN"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "metrics = pd.DataFrame(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "metrics.index = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models - Predict High/Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_text, selected_data.binary, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 14594), (6000, 14594), (24000,), (6000,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 91.0625 %\n",
      "Test Accuracy is 88.35 %\n"
     ]
    }
   ],
   "source": [
    "# build model and fit training data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# Training & Test accuracy\n",
    "print(\"Training Accuracy is\", clf.score(X_train, y_train)*100, \"%\")\n",
    "print(\"Test Accuracy is\", clf.score(X_test, y_test)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.875144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.883500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.856997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "precision  0.875144\n",
       "recall     0.883500\n",
       "fscore     0.856997\n",
       "support         NaN"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "metrics = pd.DataFrame(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "metrics.index = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
